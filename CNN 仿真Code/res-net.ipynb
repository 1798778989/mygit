{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import datetime as dtime\n",
    "import time\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "class BasicBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,filter_num,stride = 1):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filter_num,(3,3),strides = stride,padding='same')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.Activation('relu')\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(filter_num,(3,3),strides = 1,padding='same')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        if stride != 1 :\n",
    "            self.downsample = tf.keras.Sequential([\n",
    "                tf.keras.layers.Conv2D(filter_num,(1,1),strides=stride)\n",
    "            ])\n",
    "        else:\n",
    "            self.downsample = lambda x:x\n",
    "            \n",
    "    def call(self,inputs,training=None):\n",
    "        out = self.conv1(inputs)\n",
    "        out= self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        identity = self.downsample(inputs)\n",
    "        output = tf.keras.layers.add([out,identity])\n",
    "        output = tf.nn.relu(output)\n",
    "        return output\n",
    "    \n",
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self,layer_dims,num_class = 10):\n",
    "        super().__init__()\n",
    "        self.stem = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(64,(3,3),strides=(1,1)),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(1,1),padding='same')\n",
    "        ])\n",
    "        \n",
    "        self.layer1 = self.build_resblock(64,layer_dims[0])\n",
    "        self.layer2 = self.build_resblock(128,layer_dims[1],stride=2)\n",
    "        self.layer3 = self.build_resblock(256,layer_dims[2],stride=2)\n",
    "        self.layer4 = self.build_resblock(512,layer_dims[3],stride=2)\n",
    "        \n",
    "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc = tf.keras.layers.Dense(num_class)\n",
    "        \n",
    "    def call(self,inputs,training = None):\n",
    "        x = self.stem(inputs)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        \n",
    "    def build_resblock(self,filter_num,blocks,stride=1):\n",
    "        res_blocks = tf.keras.Sequential([\n",
    "            BasicBlock(filter_num,stride)\n",
    "        ])\n",
    "        for _ in range(1,blocks):\n",
    "            res_blocks.add(BasicBlock(filter_num,stride=1))\n",
    "        return res_blocks\n",
    "    \n",
    "def resnet18():\n",
    "    return ResNet([2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "\n",
    "def preprocess(x,y):\n",
    "    x = tf.cast(x,dtype=tf.float32)/255\n",
    "    y = tf.cast(y,dtype=tf.int32)\n",
    "    return x,y\n",
    "    \n",
    "(x,y),(x_test,y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "y = tf.squeeze(y,axis=1)\n",
    "y_test = tf.squeeze(y_test,axis=1)\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_db = train_db.shuffle(1000).map(preprocess).batch(100)\n",
    "\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "test_db = test_db.map(preprocess).shuffle(1000).batch(100)\n",
    "\n",
    "model = resnet18()\n",
    "model.build(input_shape = (None,32,32,3))\n",
    "model.summary()\n",
    "learn_rate = 1e-4\n",
    "epoch_num = 30\n",
    "optimizer = tf.keras.optimizers.Adam(lr = learn_rate)\n",
    "\n",
    "current_time = dtime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = '../logs/'+current_time\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "pre_loss,cur_loss = 0.,0.\n",
    "start = dtime.datetime.now()\n",
    "num_count=0\n",
    "for epoch in range(epoch_num):\n",
    "    for step,(x,y) in enumerate(train_db):\n",
    "        num_count+=1\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x)\n",
    "            y_onehot = tf.one_hot(y,depth=10)\n",
    "            \n",
    "            loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot,logits,from_logits=True))\n",
    "            pre_loss = cur_loss\n",
    "            cur_loss = loss\n",
    "        \n",
    "        grads = tape.gradient(loss,model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('train_loss',float(loss),step=num_count)\n",
    "            print('epoch:',epoch,'step:',step,'loss:',loss)\n",
    "    \n",
    "    optimizer.lr = learn_rate*(epoch_num-epoch)/epoch_num\n",
    "    if epoch>20 and cur_loss-pre_loss>0.1:\n",
    "        break;\n",
    "        \n",
    "    total_num = 0\n",
    "    total_correct = 0\n",
    "    for x,y in test_db:\n",
    "        logits = model(x)\n",
    "        prob = tf.nn.softmax(logits,axis=1)\n",
    "        pred = tf.cast(tf.argmax(prob,axis=1),dtype=tf.int32)\n",
    "        correct = tf.reduce_sum(tf.cast(tf.equal(pred,y),dtype=tf.int32))\n",
    "        \n",
    "        total_num +=x.shape[0]\n",
    "        total_correct +=int(correct)\n",
    "    acc = total_correct/total_num\n",
    "    with summary_writer.as_default():\n",
    "        tf.summary.scalar('test_acc',float(acc),step = epoch)\n",
    "    \n",
    "    if acc > 0.9:\n",
    "        break;\n",
    "    print('epoch:',epoch,'acc:',acc)\n",
    "    \n",
    "end = dtime.datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
